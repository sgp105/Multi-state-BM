{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "rough-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "import multiprocessing\n",
    "import parmap\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from sklearn.mixture import BayesianGaussianMixture as BGMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "olive-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"times new roman\"\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"cm\"\n",
    "plt.rcParams['figure.dpi'] = 75\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['axes.titlesize'] = 20 \n",
    "\n",
    "from IPython.display import set_matplotlib_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regulated-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-manufacturer",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continued-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "cimport numpy as np\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from numpy.random import uniform, normal, beta, exponential\n",
    "\n",
    "def createDirectory(str path):\n",
    "    try:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    except OSError:\n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "# hyperparameters\n",
    "D_min = 0.001\n",
    "D_max = 2\n",
    "unit_T = 0.1 # s\n",
    "unit_L = 0.167 # um\n",
    "\n",
    "########## functions for HMM\n",
    "\n",
    "def hmm_p_ini(np.ndarray[np.double_t, ndim = 2] P, int nstates): ##P : transition probability, p_ij : prob. from j to i\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] p_ini\n",
    "    cdef np.ndarray[np.double_t, ndim = 1] eig_val\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] eig_vec\n",
    "    \n",
    "    eig_val = np.real(np.linalg.eig(P)[0])\n",
    "    eig_vec = np.real(np.linalg.eig(P)[1])\n",
    "    p_ini = eig_vec[:, abs(eig_val - 1) < 0.0000001] / (eig_vec[:, abs(eig_val - 1) < 0.0000001]).sum()\n",
    "    return p_ini #column vector\n",
    "\n",
    "def logsumexpcol(np.ndarray[np.double_t, ndim = 2] x):\n",
    "    cdef np.ndarray[np.double_t] y, z\n",
    "    y = np.max(x, axis = 0)\n",
    "    x = x - y\n",
    "    z = y + np.log((np.exp(x)).sum(0))\n",
    "    z[y[:]==-np.inf] = -np.inf\n",
    "    return z\n",
    "\n",
    "def log_space_product(np.ndarray[np.double_t, ndim = 2] A, np.ndarray[np.double_t, ndim = 2] B):\n",
    "    Astack = np.stack([A]*A.shape[0]).transpose(2,1,0)\n",
    "    Bstack = np.stack([B]*B.shape[1]).transpose(1,0,2)\n",
    "    return sp.special.logsumexp(Astack+Bstack, axis=0)\n",
    "    \n",
    "def hmm_emission(np.ndarray[np.double_t, ndim = 1] obs,\n",
    "                   np.ndarray[np.double_t, ndim = 2] sigma):\n",
    "    return -np.log(2*np.pi*(sigma**2))/2 - (obs**2)/(2*(sigma**2))\n",
    "\n",
    "def hmm_main(np.ndarray[np.double_t, ndim = 2] obs,   #obs : column vector, displacements\n",
    "             np.ndarray[np.double_t, ndim = 2] P,\n",
    "             np.ndarray[np.double_t, ndim = 2] sigma, #sigma : column vector\n",
    "             int nstates):\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] pstate_ini, logPT, logpstatexprev, logpstatex  #pstate_ini : column vector\n",
    "    cdef np.ndarray[np.double_t, ndim = 1] obs_cur # value\n",
    "    cdef int i\n",
    "    \n",
    "    pstate_ini = hmm_p_ini(P, nstates).copy()\n",
    "    logPT = np.log(P.T).copy()\n",
    "    logpstatexprev = np.log(pstate_ini).copy()\n",
    "    \n",
    "    for i in range(obs.shape[0]):\n",
    "        obs_cur = obs[i].copy()\n",
    "        logpstatex = hmm_emission(obs_cur, sigma) + logpstatexprev\n",
    "        logpstatexprev = logsumexpcol(logPT + logpstatex)[:, None]\n",
    "\n",
    "    return logsumexpcol(logpstatex)  #log likelihood ?\n",
    "\n",
    "\n",
    "\n",
    "########## functions for nested sampling\n",
    "def prior_nonuniform(int nstates, int order):\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] alpha\n",
    "    cdef int row, col\n",
    "    \n",
    "    if order < nstates:\n",
    "        return uniform(D_min, D_max)\n",
    "    else:\n",
    "        alpha = np.ones((nstates, nstates)) * (1 + 0.5 / (nstates - 1))\n",
    "        alpha[range(nstates), range(nstates)] = 10.5\n",
    "        row = (int)((order - nstates) / nstates)\n",
    "        col = order % nstates\n",
    "        return beta(alpha[row, col], alpha[row + 1:, col].sum())       \n",
    "\n",
    "def initial_stepsize(int nstates):\n",
    "    cdef np.ndarray[np.double_t, ndim = 1] stepsize\n",
    "    \n",
    "    stepsize = np.zeros(nstates**2, dtype = float)\n",
    "    if nstates == 1:\n",
    "        stepsize[0] = np.sqrt(1/12) * (D_max - D_min) # step for diffusivity\n",
    "    elif nstates == 2:\n",
    "        stepsize[:2] = np.sqrt(1/12) * (D_max - D_min) # step for diffusivity\n",
    "        stepsize[2:4] = np.sqrt(1/12)\n",
    "    elif nstates == 3:\n",
    "        stepsize[:3] = np.sqrt(1/12) * (D_max - D_min) # step for diffusivity\n",
    "        stepsize[3:6] = np.sqrt(1/18)\n",
    "        stepsize[6:9] = np.sqrt(1/12)\n",
    "    elif nstates == 4:\n",
    "        stepsize[:4] = np.sqrt(1/12) * (D_max - D_min) # step for diffusivity\n",
    "        stepsize[4:8] = np.sqrt(3/5)/4\n",
    "        stepsize[8:12] = np.sqrt(1/18)\n",
    "        stepsize[12:16] = np.sqrt(1/12)\n",
    "    stepsize *= 0.8\n",
    "    return stepsize\n",
    "        \n",
    "def adjust_stepsize(np.ndarray[np.double_t, ndim = 1] stepsize,\n",
    "                    np.ndarray[np.int_t, ndim = 1] reject,\n",
    "                    int nsweep,\n",
    "                    double target_rate):\n",
    "    cdef int i\n",
    "    for i in range(len(stepsize)):\n",
    "        stepsize[i] = np.min([stepsize[i] * np.exp(target_rate - (reject[i]/nsweep)), 1])\n",
    "    return stepsize\n",
    "\n",
    "def convert_theta(np.ndarray[np.double_t, ndim = 1] theta, int nstates):\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] sigma, P\n",
    "    cdef int i, j\n",
    "    \n",
    "    # diffusivity to sigma\n",
    "    sigma = np.sqrt(2 * theta[:nstates] * unit_T)[:, None]\n",
    "    P = np.ones((nstates, nstates), dtype = float)\n",
    "    # to transition probability\n",
    "\n",
    "    if nstates == 1 :\n",
    "        return sigma, P\n",
    "    else:\n",
    "        for i in range(nstates - 1):  # row\n",
    "            for j in range(nstates):  # column\n",
    "                if i == 0: #first row\n",
    "                    P[i, j] = theta[nstates + j]\n",
    "                elif i == 1:\n",
    "                    P[i, j] = (1 - P[i-1, j]) * theta[nstates*2 + j]\n",
    "                elif i == 2:\n",
    "                    P[i, j] = (1 - P[i-1, j] - P[i-2, j]) * theta[nstates*3 + j]\n",
    "        P[nstates - 1, :] = 1 - P[:nstates - 1, :].sum(axis = 0)\n",
    "        return sigma, P\n",
    "\n",
    "def propagator(double theta_prev,  # previous value of theta\n",
    "               double stepsize,  # step size of random walker for each direction\n",
    "               double rn):  # standard normal random number\n",
    "    return theta_prev + stepsize * rn\n",
    "\n",
    "def verification(theta, int nstates, int index):\n",
    "    if index < nstates:\n",
    "        if D_min <= theta <= D_max:\n",
    "            return 1\n",
    "        else:\n",
    "            return -np.inf\n",
    "    else:\n",
    "        if 0 <= theta <= 1:\n",
    "            return 1\n",
    "        else:\n",
    "            return -np.inf\n",
    "\n",
    "def acceptance_nonuniform(double theta, double theta_prev, int nstates, int index):\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] alpha\n",
    "    cdef int row, col\n",
    "    \n",
    "    if index < nstates: # diffusivity\n",
    "        return 1\n",
    "    else:\n",
    "        alpha = np.ones((nstates, nstates)) * (1 + 0.5 / (nstates - 1))\n",
    "        alpha[range(nstates), range(nstates)] = 10.5\n",
    "        row = (int)((index - nstates) / nstates)\n",
    "        col = index % nstates\n",
    "        return sp.stats.beta.pdf(theta, alpha[row, col], alpha[row + 1:, col].sum()) / sp.stats.beta.pdf(theta_prev, alpha[row, col], alpha[row + 1:, col].sum())\n",
    "        \n",
    "def nested_main(np.ndarray[np.double_t, ndim = 2] obs,  # input displacements, column vector (length * dimension)\n",
    "                int nwalkers,  # number of random walkers\n",
    "                int imax,  # maximum sampling iteration\n",
    "                double stop_ratio,  # allowed ratio of Z_remain / Z, ~ 0.0001\n",
    "                double reject_rate,  # targec rejection rate, ~ 0.25\n",
    "                int nsweep,  # number of random walk step per random walk (in MH algorithm)\n",
    "                int nstates):  # number of states of given model\n",
    "    cdef int i, j, k, min_index, rcnt_n, rcnt_u\n",
    "    cdef int nparams\n",
    "    cdef double start, runningtime\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] walker # active walkers [walker index, parameter index]  #### last parameter: likelihood value\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] series # series of selected parameters and their likelihood values\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] new_walker # new walker [sampling time, parameter index]  #### last parameter: likelihood\n",
    "    cdef np.ndarray[np.double_t, ndim = 1] stepsize, walker_keep, stnormal, unif\n",
    "    cdef np.ndarray[np.int_t, ndim = 1] reject\n",
    "    cdef double evidence, evidence_remain, logweight, minL\n",
    "    \n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    nparams = nstates ** 2\n",
    "    walker = np.zeros((nwalkers, nparams + 1), dtype = float)  # walker[walker index, parameter index]\n",
    "    stepsize = np.zeros(nparams, dtype = float)\n",
    "    series = np.zeros((imax, nparams + 1), dtype = float)\n",
    "    \n",
    "    \n",
    "    # determine initial step sizes for each parameter space, step size : stdev of Gaussian propagator\n",
    "    stepsize = initial_stepsize(nstates)\n",
    "    \n",
    "    # distribute walkers to follow prior distribution and obtain their likelihood\n",
    "    for i in range(nwalkers):\n",
    "        for j in range(nparams):\n",
    "            #walker[i, j] = prior_sampling(nstates, j)\n",
    "            walker[i, j] = prior_nonuniform(nstates, j)\n",
    "            #walker[i, j] = prior_jeffrey(nstates, j)\n",
    "        sigma, P = convert_theta(walker[i, :nparams], nstates)\n",
    "        walker[i, nparams] = hmm_main(obs, P, sigma, nstates)  #log likelihood of first parameters\n",
    "    \n",
    "    # nested sampling iteration\n",
    "    evidence = -np.inf # initial log evidence\n",
    "    logweight = np.log(1 / (nwalkers + 1)) # initial log weight\n",
    "\n",
    "    \n",
    "    for i in range(imax):\n",
    "        min_index = np.argmin(walker[:, nparams])\n",
    "        series[i] = walker[min_index, :].copy()  # keep parameters and log likelihood of minimum likelihood walker\n",
    "        minL = series[i, nparams]\n",
    "        evidence = sp.special.logsumexp([evidence, minL + logweight])\n",
    "        \n",
    "        new_walker = np.zeros((nsweep + 1, nparams + 1))\n",
    "        walker_keep = np.zeros(nparams + 1)\n",
    "        \n",
    "        while(1):  # choose a new random walker from the remaining K-1 walkers\n",
    "            new_walker[0, :] = walker[np.random.randint(0, nwalkers), :].copy()\n",
    "            if new_walker[0, nparams] != minL:\n",
    "                break\n",
    "        walker_keep = new_walker[0, :].copy()\n",
    "        \n",
    "        ######## initialization\n",
    "        rcnt_n = 0\n",
    "        stnormal = normal(0, 1, nsweep * nparams)\n",
    "        rcnt_u = 0\n",
    "        unif = uniform(0, 1, nsweep * nparams)\n",
    "        reject = np.zeros(nparams, dtype = int)\n",
    "        ########\n",
    "        for j in range(1, nsweep + 1): # metropolis within gibbs\n",
    "            new_walker[j, :] = walker_keep.copy()\n",
    "            for k in range(nparams):\n",
    "                new_walker[j, k] = propagator(walker_keep[k], stepsize[k], stnormal[rcnt_n])  #previous position, parameter index, step size of random walk\n",
    "                rcnt_n += 1\n",
    "                \n",
    "                # reject forbidden parameters\n",
    "                new_walker[j, nparams] = verification(new_walker[j, k], nstates, k)\n",
    "                if new_walker[j, nparams] == -np.inf:\n",
    "                    new_walker[j, :] = walker_keep.copy()\n",
    "                    reject[k] += 1\n",
    "                else:\n",
    "                    sigma, P = convert_theta(new_walker[j, :nparams], nstates)\n",
    "                    new_walker[j, nparams] = hmm_main(obs, P, sigma, nstates)  #log likelihood of the sampled parameter set\n",
    "                    \n",
    "                    if new_walker[j, nparams] <= minL:  # reject -- likelihood boundary\n",
    "                        new_walker[j, :] = walker_keep.copy()\n",
    "                        reject[k] += 1\n",
    "                    #elif acceptance(new_walker[j, k], walker_keep[k], nstates, k) < unif[rcnt_u]:  # reject -- metropolis\n",
    "                    elif acceptance_nonuniform(new_walker[j, k], walker_keep[k], nstates, k) < unif[rcnt_u]:  # reject -- metropolis\n",
    "                    #elif acceptance_jeffrey(new_walker[j, k], walker_keep[k], nstates, k) < unif[rcnt_u]:  # reject -- metropolis\n",
    "                        new_walker[j, :] = walker_keep.copy()\n",
    "                        reject[k] += 1\n",
    "                    rcnt_u += 1\n",
    "                walker_keep = new_walker[j, :].copy()\n",
    "        \n",
    "        \n",
    "        # replace walker having minumum likelihood with a new better walker\n",
    "        walker[min_index, :] = new_walker[nsweep, :].copy()\n",
    "        logweight += np.log(nwalkers / (nwalkers + 1))\n",
    "        \n",
    "        #calculate Z_remain\n",
    "        evidence_remain = -np.inf\n",
    "        for j in range(nwalkers):\n",
    "            evidence_remain = sp.special.logsumexp([evidence_remain, walker[j, nparams]])\n",
    "        evidence_remain += logweight\n",
    "        \n",
    "        # check stop ratio\n",
    "        if evidence_remain - evidence < np.log(stop_ratio):\n",
    "            evidence = sp.special.logsumexp([evidence, evidence_remain])  # final evidence\n",
    "            runningtime = time.time() - start\n",
    "            print('nstate = {} done, {} seconds'.format(nstates, runningtime))\n",
    "            break\n",
    "        \n",
    "        if i%100 == 0:\n",
    "            print('i:', i)\n",
    "            print('log(Z_remain / Z):', evidence_remain - evidence)\n",
    "        \n",
    "        stepsize = adjust_stepsize(stepsize, reject, nsweep, reject_rate)\n",
    "        \n",
    "    return evidence, series[:i+1, :], walker\n",
    "\n",
    "def mp_nested_sampling(np.ndarray[np.int_t, ndim = 1] indices,\n",
    "                       int nwalkers,\n",
    "                       int imax,\n",
    "                       double stop_ratio,\n",
    "                       double reject_rate,\n",
    "                       int nsweep,\n",
    "                       str path,\n",
    "                       str protein):\n",
    "\n",
    "    cdef np.ndarray[np.double_t, ndim = 1] evidence\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] prob, mle\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] series, temp_walker, walker, totalseries\n",
    "    cdef int i, j, index, max_index, model\n",
    "    \n",
    "    prob = np.zeros((len(indices), 3))\n",
    "    mle = np.zeros((len(indices), 9))\n",
    "    \n",
    "    for i, index in enumerate(indices):\n",
    "        evidence = np.ones(3) * (-np.inf)\n",
    "        trj = np.loadtxt('{}/{}long{}.txt'.format(path, protein, index))\n",
    "        obs_v = np.diff(trj)[:, None]\n",
    "        \n",
    "        for j in range(3):\n",
    "            evidence[j], series, temp_walker = nested_main(obs_v, nwalkers, imax, stop_ratio, reject_rate, nsweep, j+1)\n",
    "            totalseries = np.zeros((len(series) + len(temp_walker), (j+1) ** 2 + 1))  # j+1 : nstates\n",
    "            totalseries[:len(series), :] = series.copy()\n",
    "            totalseries[len(series):, :] = temp_walker.copy()\n",
    "            \n",
    "            createDirectory('{}/results'.format(path))\n",
    "            \n",
    "            #save the sampled parameters of each state\n",
    "            with open('{}/results/{}totalseries{}state.pkl'.format(path, index, j+1), 'wb') as f:\n",
    "                pickle.dump(totalseries, f)\n",
    "            \n",
    "            if j == np.argmax(evidence):\n",
    "                walker = temp_walker.copy()\n",
    "            #if j == 0:\n",
    "            #    walker = temp_walker.copy()\n",
    "            #elif j > 0 and evidence[j] > evidence[j-1]:\n",
    "            #    walker = temp_walker.copy()\n",
    "        \n",
    "        #save the model probabilities\n",
    "        prob[i, :] = evidence - np.max(evidence)  # unnormalized log probabilities\n",
    "        prob[i, :] = np.exp(prob[i, :]) / np.exp(sp.special.logsumexp(prob[i, :]))  # normalized probabilities\n",
    "        \n",
    "        with open('{}/results/evidence{}.pkl'.format(path, index), 'wb') as f:\n",
    "            pickle.dump(evidence, f)\n",
    "        with open('{}/results/prob{}.pkl'.format(path, index), 'wb') as f:\n",
    "            pickle.dump(prob[i, :], f)\n",
    "        \"\"\"\n",
    "        model = np.argmax(prob[i, :]) + 1 #optimal nstates\n",
    "        \n",
    "        #save the maximum likelihood estimator of the best-fit model\n",
    "        max_index = np.argmax(walker[:, model ** 2])\n",
    "        mle[i, :model ** 2] = walker[max_index, :model ** 2].copy()\n",
    "        with open('{}/results/MLE{}.pkl'.format(path, index), 'wb') as f:\n",
    "            pickle.dump(walker[max_index, :], f)\n",
    "        \"\"\"     \n",
    "    return 0\n",
    "\n",
    "def NS_Params(str prior_type,   # uniform / jeffrey\n",
    "              str selection_method,   # Bayesian / AIC / BIC\n",
    "              str path,\n",
    "              int fnum\n",
    "             ):\n",
    "    cdef int i, j, k, nstates, nparams\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] series, P, alpha, IC\n",
    "    cdef np.ndarray[np.double_t, ndim = 1] prior, D, posterior, MAP, MLE, IC_bayes\n",
    "    cdef double prior_D, prior_P, norm\n",
    "    cdef np.ndarray[np.int_t, ndim = 1] model\n",
    "    \n",
    "    \n",
    "    #### model selection\n",
    "        \n",
    "    model = np.zeros(fnum, dtype = int)\n",
    "    if selection_method == 'AIC':\n",
    "        with open('{}/results/AIC.pkl'.format(path), 'rb') as f:\n",
    "            IC = pickle.load(f)\n",
    "        model = np.argmin(IC, axis = 1).astype(int) + 1\n",
    "            \n",
    "    elif selection_method == 'Bayesian':\n",
    "        for i in range(fnum):\n",
    "            with open('{}/results/prob{}.pkl'.format(path, i + 1), 'rb') as f:\n",
    "                IC_bayes = pickle.load(f)\n",
    "            model[i] = np.argmax(IC_bayes) + 1\n",
    "    \n",
    "    #calculate prior values of nested samples\n",
    "    \n",
    "    if prior_type == 'uniform':\n",
    "        for i in range(fnum):\n",
    "            nstates = model[i]\n",
    "            nparams = nstates ** 2\n",
    "            \n",
    "            if nstates != 1:\n",
    "                alpha = np.ones((nstates, nstates)) * (1 + 0.5 / (nstates - 1))\n",
    "                alpha[range(nstates), range(nstates)] = 10.5\n",
    "            \n",
    "                with open('{}/results/{}totalseries{}state.pkl'.format(path, i+1, nstates), 'rb') as f:\n",
    "                    series = pickle.load(f)\n",
    "                prior = np.zeros(series.shape[0])\n",
    "                posterior = np.zeros(series.shape[0])\n",
    "            \n",
    "                for j in range(series.shape[0]):\n",
    "                    D = series[j, :nstates].copy()\n",
    "                    prior_D = np.log(1/(D_max - D_min)) * nstates\n",
    "                \n",
    "                    _, P = convert_theta(series[j], nstates)\n",
    "                    prior_P = 0\n",
    "                    for k in range(nstates):\n",
    "                        prior_P += np.log(sp.stats.dirichlet.pdf(P[:, k], alpha[:, k]))\n",
    "            \n",
    "                    prior[j] = prior_D + prior_P\n",
    "                    posterior[j] = prior[j] + series[j, nparams]\n",
    "            \n",
    "            elif nstates == 1:\n",
    "                with open('{}/results/{}totalseries{}state.pkl'.format(path, i+1, nstates), 'rb') as f:\n",
    "                    series = pickle.load(f)\n",
    "                prior = np.zeros(series.shape[0])\n",
    "                posterior = np.zeros(series.shape[0])\n",
    "                \n",
    "                for j in range(series.shape[0]):\n",
    "                    D = series[j, :nstates].copy()\n",
    "                    prior_D = np.log(1/(D_max - D_min)) * nstates\n",
    "            \n",
    "                    prior[j] = prior_D\n",
    "                    posterior[j] = prior[j] + series[j, nparams]\n",
    "            \n",
    "            MAP = series[np.argmax(posterior), :].copy()\n",
    "            MLE = series[np.argmax(series[:, nparams]), :].copy()\n",
    "            with open('{}/results/MAP{}_{}.pkl'.format(path, i+1, selection_method), 'wb') as f:\n",
    "                pickle.dump(MAP, f)\n",
    "            with open('{}/results/MLE{}_{}.pkl'.format(path, i+1, selection_method), 'wb') as f:\n",
    "                pickle.dump(MLE, f)\n",
    "                \n",
    "    return 0\n",
    "\n",
    "def sample_sorting(np.ndarray[np.double_t, ndim = 1] theta, int nstates):\n",
    "    cdef int i, j\n",
    "    cdef np.ndarray[np.double_t, ndim = 1] sigma\n",
    "    cdef np.ndarray[np.double_t, ndim = 2] P\n",
    "    cdef double temp_sigma\n",
    "    cdef np.ndarray[np.double_t, ndim = 1] temp_P\n",
    "    \n",
    "    sigma = convert_theta(theta, nstates)[0].flatten()\n",
    "    P = convert_theta(theta, nstates)[1]\n",
    "    if nstates > 1:\n",
    "        for i in range(1, nstates):\n",
    "            for j in range(0, nstates - i):\n",
    "                if sigma[j] > sigma[j+1]:\n",
    "                    #switch sigma\n",
    "                    temp_sigma = sigma[j]\n",
    "                    sigma[j] = sigma[j+1]\n",
    "                    sigma[j+1] = temp_sigma\n",
    "                    #switch P\n",
    "                    temp_P = P[j, :].copy()\n",
    "                    P[j, :] = P[j+1, :].copy()\n",
    "                    P[j+1, :] = temp_P.copy()\n",
    "                    temp_P = P[:, j].copy()\n",
    "                    P[:, j] = P[:, j+1].copy()\n",
    "                    P[:, j+1] = temp_P.copy()\n",
    "    return sigma ** 2 / 2 / unit_T, P\n",
    "\n",
    "def dp_to_theta(np.ndarray[np.double_t, ndim = 1] D, np.ndarray[np.double_t, ndim = 2] P, int nstates):\n",
    "    cdef int i, j\n",
    "    cdef np.ndarray[np.double_t, ndim = 1] theta\n",
    "    \n",
    "    theta = np.zeros(nstates ** 2)\n",
    "    theta[:nstates] = D.copy()\n",
    "    \n",
    "    if nstates != 1:\n",
    "        for i in range(nstates - 1):\n",
    "            for j in range(nstates):\n",
    "                if i == 0:\n",
    "                    theta[nstates * (i + 1) + j] = P[i, j]\n",
    "                elif i == 1:\n",
    "                    theta[nstates * (i + 1) + j] = P[i, j] / (1 - P[i-1, j])\n",
    "                elif i == 2:\n",
    "                    theta[nstates * (i + 1) + j] = P[i, j] / (1 - P[i-1, j] - P[i-2, j])\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-still",
   "metadata": {},
   "source": [
    "# Nested sampling run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-wiring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mshlong1.txt' 'mshlong2.txt' 'mshlong3.txt' 'mshlong4.txt'\n",
      " 'mshlong5.txt' 'mshlong6.txt' 'mshlong7.txt' 'mshlong8.txt'\n",
      " 'mshlong9.txt' 'mshlong10.txt' 'mshlong11.txt' 'mshlong12.txt'\n",
      " 'mshlong13.txt' 'mshlong14.txt' 'mshlong15.txt' 'mshlong16.txt'\n",
      " 'mshlong17.txt' 'mshlong18.txt' 'mshlong19.txt' 'mshlong20.txt'\n",
      " 'mshlong21.txt' 'mshlong22.txt' 'mshlong23.txt' 'mshlong24.txt'\n",
      " 'mshlong25.txt' 'mshlong26.txt' 'mshlong27.txt' 'mshlong28.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d046f19f1cec484187392451bec1fea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'MSH2/5nM'\n",
    "protein = 'msh'\n",
    "fnames = np.genfromtxt('{}/longnames.txt'.format(path), dtype = 'str')\n",
    "fnum = len(fnames)\n",
    "findices = np.arange(1, fnum + 1)\n",
    "num_cores = min(40, fnum)\n",
    "indices = np.array_split(findices, num_cores)\n",
    "\n",
    "print(fnames)\n",
    "for i in range(fnum):\n",
    "    globals()['{}long{}'.format(protein, i + 1)] = np.genfromtxt('{}/{}'.format(path, fnames[i]))\n",
    "\n",
    "parmap.map(mp_nested_sampling, indices, 200, 100000, 0.0001, 0.25, 30, path, protein, pm_pbar = True, pm_processes = num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-reader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mshlong1.txt' 'mshlong2.txt' 'mshlong3.txt' 'mshlong4.txt'\n",
      " 'mshlong5.txt' 'mshlong6.txt' 'mshlong7.txt' 'mshlong8.txt'\n",
      " 'mshlong9.txt' 'mshlong10.txt' 'mshlong11.txt' 'mshlong12.txt'\n",
      " 'mshlong13.txt' 'mshlong14.txt' 'mshlong15.txt' 'mshlong16.txt'\n",
      " 'mshlong17.txt' 'mshlong18.txt' 'mshlong19.txt' 'mshlong20.txt'\n",
      " 'mshlong21.txt' 'mshlong22.txt' 'mshlong23.txt' 'mshlong24.txt'\n",
      " 'mshlong25.txt' 'mshlong26.txt' 'mshlong27.txt' 'mshlong28.txt'\n",
      " 'mshlong29.txt' 'mshlong30.txt' 'mshlong31.txt' 'mshlong32.txt'\n",
      " 'mshlong33.txt' 'mshlong34.txt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ddaee99ad74fd980d63392f0d68013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = 'MSH2/10nM'\n",
    "protein = 'msh'\n",
    "fnames = np.genfromtxt('{}/longnames.txt'.format(path), dtype = 'str')\n",
    "fnum = len(fnames)\n",
    "findices = np.arange(1, fnum + 1)\n",
    "num_cores = min(40, fnum)\n",
    "indices = np.array_split(findices, num_cores)\n",
    "\n",
    "print(fnames)\n",
    "for i in range(fnum):\n",
    "    globals()['{}long{}'.format(protein, i + 1)] = np.genfromtxt('{}/{}'.format(path, fnames[i]))\n",
    "\n",
    "parmap.map(mp_nested_sampling, indices, 200, 100000, 0.0001, 0.25, 30, path, protein, pm_pbar = True, pm_processes = num_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assisted-scoop",
   "metadata": {},
   "source": [
    "# AIC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cooked-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "fnums = [28, 34]\n",
    "#paths = ['MSH2/5nM', 'MSH2/10nM']\n",
    "paths = ['MSH2/5nM', 'MSH2/10nM']\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    globals()['set{}_AIC'.format(i+1)] = np.zeros((fnums[i], 3))\n",
    "    for j in range(fnums[i]):\n",
    "        temp_AIC = np.inf\n",
    "        for k in range(3):\n",
    "            nstates = k + 1\n",
    "            with open('{}/results/{}totalseries{}state.pkl'.format(path, j+1, nstates), 'rb') as f:\n",
    "                temp = pickle.load(f)\n",
    "            temp_MLE = temp[np.argmax(temp[:, nstates**2]), :]\n",
    "            globals()['set{}_AIC'.format(i+1)][j, k] = 2 * (nstates ** 2) - 2 * temp_MLE[nstates ** 2]\n",
    "            \n",
    "            if globals()['set{}_AIC'.format(i+1)][j, k] < temp_AIC: # model selection\n",
    "                temp_AIC = globals()['set{}_AIC'.format(i+1)][j, k]\n",
    "                globals()['set{}_MLE{}'.format(i+1, j+1)] = temp_MLE.copy() # MLE with minimum AIC\n",
    "\n",
    "    with open('{}/results/AIC.pkl'.format(path), 'wb') as f:\n",
    "        pickle.dump(globals()['set{}_AIC'.format(i+1)], f)\n",
    "        \n",
    "AIC = np.concatenate((set1_AIC, set2_AIC), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-satin",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "offensive-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'MSH2/5nM'\n",
    "fnum = 28\n",
    "#path = 'MSH2/10nM'\n",
    "#fnum = 34\n",
    "\n",
    "model_AIC = np.zeros(fnum, dtype = int)\n",
    "with open('{}/results/AIC.pkl'.format(path), 'rb') as f:\n",
    "    IC = pickle.load(f)\n",
    "model_AIC = np.argmin(IC, axis = 1) + 1\n",
    "            \n",
    "model_Bayes = np.zeros(fnum, dtype = int)\n",
    "for i in range(fnum):\n",
    "    with open('{}/results/prob{}.pkl'.format(path, i + 1), 'rb') as f:\n",
    "        prob = pickle.load(f)\n",
    "    model_Bayes[i] = np.argmax(prob) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "detailed-browse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1,\n",
       "       2, 1, 2, 1, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_AIC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interested-ranking",
   "metadata": {},
   "source": [
    "# Parameter estimation (MLE, MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['MSH2/5nM', 'MSH2/10nM']\n",
    "fnums = [28, 34]\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    fnum = fnums[i]\n",
    "    NS_Params('uniform', 'AIC', path, fnum)\n",
    "    NS_Params('uniform', 'Bayesian', path, fnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "latin-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths = ['MSH2/5nM', 'MSH2/10nM']\n",
    "paths = ['MSH2/5nM/results', 'MSH2/10nM/results']\n",
    "protein = 'msh'\n",
    "\n",
    "fnum = [28, 34]\n",
    "AIC_MLE_ds = []\n",
    "AIC_MAP_ds = []\n",
    "cnt = 0\n",
    "\n",
    "####--AIC, MLE\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    for j in range(fnum[i]):\n",
    "        with open('{}/MLE{}_{}.pkl'.format(path, j+1, 'AIC'), 'rb') as f:\n",
    "            temp = pickle.load(f)\n",
    "        temp = temp.flatten()\n",
    "        for k in range(np.sqrt(len(temp)-1).astype(int)):\n",
    "            AIC_MLE_ds.append(temp[k])\n",
    "        \n",
    "####--AIC, MLE\n",
    "\n",
    "####--AIC, MAP\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    for j in range(fnum[i]):\n",
    "        with open('{}/MAP{}_{}.pkl'.format(path, j+1, 'AIC'), 'rb') as f:\n",
    "            temp = pickle.load(f)\n",
    "        temp = temp.flatten()\n",
    "        for k in range(np.sqrt(len(temp)-1).astype(int)):\n",
    "            AIC_MAP_ds.append(temp[k])\n",
    "\n",
    "####--AIC, MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "worse-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths = ['MSH2/5nM', 'MSH2/10nM']\n",
    "paths = ['MSH2/5nM/results', 'MSH2/10nM/results']\n",
    "protein = 'msh'\n",
    "\n",
    "fnum = [28, 34]\n",
    "Bayes_MLE_ds = []\n",
    "Bayes_MAP_ds = []\n",
    "cnt = 0\n",
    "\n",
    "####--AIC, MLE\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    for j in range(fnum[i]):\n",
    "        with open('{}/MLE{}_{}.pkl'.format(path, j+1, 'Bayesian'), 'rb') as f:\n",
    "            temp = pickle.load(f)\n",
    "        temp = temp.flatten()\n",
    "        for k in range(np.sqrt(len(temp)-1).astype(int)):\n",
    "            Bayes_MLE_ds.append(temp[k])\n",
    "        \n",
    "####--AIC, MLE\n",
    "\n",
    "\n",
    "####--AIC, MAP\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    for j in range(fnum[i]):\n",
    "        with open('{}/MAP{}_{}.pkl'.format(path, j+1, 'Bayesian'), 'rb') as f:\n",
    "            temp = pickle.load(f)\n",
    "        temp = temp.flatten()\n",
    "        for k in range(np.sqrt(len(temp)-1).astype(int)):\n",
    "            Bayes_MAP_ds.append(temp[k])\n",
    "\n",
    "####--AIC, MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-blast",
   "metadata": {},
   "source": [
    "# Parameter clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-colon",
   "metadata": {},
   "source": [
    "### AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "described-syria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "weight: 0.48439322854246064\n",
      "mu: [0.35995965]\n",
      "var: 0.07172205602884993\n",
      "36\n",
      "weight: 0.33580007109852694\n",
      "mu: [0.06048195]\n",
      "var: 0.044563358566743254\n",
      "16\n",
      "weight: 0.1650178099059343\n",
      "mu: [0.00446527]\n",
      "var: 0.2962464061899724\n",
      "0\n",
      "weight: 0.01478889045307804\n",
      "mu: [0.09045379]\n",
      "var: 0.060119975657845166\n",
      "49\n",
      "weight: 0.4842005173504086\n",
      "mu: [0.35193424]\n",
      "var: 0.06636718003045726\n",
      "35\n",
      "weight: 0.32333521269600024\n",
      "mu: [0.06448872]\n",
      "var: 0.038953986386944014\n",
      "17\n",
      "weight: 0.17764635549279736\n",
      "mu: [0.00594333]\n",
      "var: 0.30606775445160883\n",
      "0\n",
      "weight: 0.014817914460793837\n",
      "mu: [0.09286594]\n",
      "var: 0.060050563777616764\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 187.5x187.5 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors = ['tab:red', 'tab:blue', 'tab:grey', 'tab:grey']\n",
    "\n",
    "gs = plt.GridSpec(1, 2, wspace = 0, width_ratios=[1, 1])\n",
    "fig = plt.figure(figsize = (2.5, 2.5))\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax2 = fig.add_subplot(gs[1], sharey = ax1)\n",
    "\n",
    "####--BGMM, MLE & MLE plot\n",
    "\n",
    "AIC_MLE_ds = np.array(AIC_MLE_ds)\n",
    "bgmm = BGMM(n_components = 4,\n",
    "            max_iter = 50,\n",
    "            n_init = 50,\n",
    "            init_params = 'kmeans',\n",
    "            random_state = 1,\n",
    "            weight_concentration_prior = 20,\n",
    "            mean_precision_prior = 0.5,\n",
    "            covariance_type = 'spherical',\n",
    "#            covariance_prior = 0.6,\n",
    "            covariance_prior = 0.3,\n",
    "            degrees_of_freedom_prior = 5).fit(np.log10(AIC_MLE_ds[:, None]))\n",
    "bgmm_labels = bgmm.predict(np.log10(AIC_MLE_ds[:, None])) \n",
    "    \n",
    "mu = bgmm.means_\n",
    "var = bgmm.covariances_\n",
    "weights = bgmm.weights_\n",
    "\n",
    "hist, bins = np.histogram(np.log10(AIC_MLE_ds), density = True, bins = np.linspace(-3, 0.5, 35))\n",
    "bins = (bins[:len(bins) - 1] + (bins[1] - bins[0]) / 2).copy()\n",
    "\n",
    "for i in range(4):\n",
    "    print(len(AIC_MLE_ds[bgmm_labels == i]))\n",
    "    print('weight:', weights[i])\n",
    "    print('mu:', 10**mu[i])\n",
    "    print('var:', var[i])\n",
    "\n",
    "for i in range(3):\n",
    "    globals()['AICMLEbound{}'.format(i+1)] = np.min(AIC_MLE_ds[bgmm_labels == i])\n",
    "    globals()['index{}'.format(i+1)] = np.where(globals()['AICMLEbound{}'.format(i+1)] <= 10 ** bins)[0][0]\n",
    "\n",
    "ax1.barh(10**bins[index1:], hist[index1:], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index1:], color = colors[0], alpha = 0.4)\n",
    "ax1.barh(10**bins[index2:index1], hist[index2:index1], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index2:index1], color = colors[1], alpha = 0.4)\n",
    "ax1.barh(10**bins[index3:index2], hist[index3:index2], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index3:index2], color = colors[2], alpha = 0.4)\n",
    "ax1.barh(10**bins[:index3], hist[:index3], height = (bins[1] - bins[0]) * 2.3 * 10**bins[:index3], color = colors[3], alpha = 0.4)\n",
    "\n",
    "ax1.invert_xaxis()\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xlim(1.1, 0)\n",
    "ax1.set_ylim(0.0005, 5)\n",
    "ax1.set_xticks([1, 0.5])\n",
    "ax1.set_title('MLE')\n",
    "\n",
    "xspace2 = np.linspace(1, 0, 5)\n",
    "for i in range(3):\n",
    "    ax1.plot(xspace2, 10**mu[i] * np.ones(len(xspace2)), '--', linewidth = 2, color = colors[i])\n",
    "\n",
    "####--BGMM, MLE & MLE plot\n",
    "\n",
    "\n",
    "####-MAP plot\n",
    "\n",
    "AIC_MAP_ds = np.array(AIC_MAP_ds)\n",
    "bgmm = BGMM(n_components = 4,\n",
    "            max_iter = 50,\n",
    "            n_init = 50,\n",
    "            init_params = 'kmeans',\n",
    "            random_state = 1,\n",
    "            weight_concentration_prior = 20,\n",
    "            mean_precision_prior = 0.5,\n",
    "            covariance_type = 'spherical',\n",
    "#            covariance_prior = 0.6,\n",
    "            covariance_prior = 0.3,\n",
    "            degrees_of_freedom_prior = 5).fit(np.log10(AIC_MAP_ds[:, None]))\n",
    "bgmm_labels = bgmm.predict(np.log10(AIC_MAP_ds[:, None])) \n",
    "    \n",
    "mu = bgmm.means_\n",
    "var = bgmm.covariances_\n",
    "weights = bgmm.weights_\n",
    "    \n",
    "hist, bins = np.histogram(np.log10(AIC_MAP_ds), density = True, bins = np.linspace(-3, 0.5, 35))\n",
    "bins = (bins[:len(bins) - 1] + (bins[1] - bins[0]) / 2).copy()\n",
    "\n",
    "for i in range(4):\n",
    "    print(len(AIC_MAP_ds[bgmm_labels == i]))\n",
    "    print('weight:', weights[i])\n",
    "    print('mu:', 10**mu[i])\n",
    "    print('var:', var[i])\n",
    "\n",
    "for i in range(3):\n",
    "    globals()['AICMAPbound{}'.format(i+1)] = np.min(AIC_MAP_ds[bgmm_labels == i])\n",
    "    globals()['index{}'.format(i+1)] = np.where(globals()['AICMAPbound{}'.format(i+1)] <= 10 ** bins)[0][0]\n",
    "\n",
    "ax2.barh(10**bins[index1:], hist[index1:], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index1:], color = colors[0], alpha = 0.4)\n",
    "ax2.barh(10**bins[index2:index1], hist[index2:index1], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index2:index1], color = colors[1], alpha = 0.4)\n",
    "ax2.barh(10**bins[index3:index2], hist[index3:index2], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index3:index2], color = colors[2], alpha = 0.4)\n",
    "\n",
    "#yspace = np.linspace(-3, 0.2, 1000)\n",
    "#for i in range(len(mu)):\n",
    "#    ax2.plot(weights[i].flatten() * norm.pdf(yspace, mu[i].flatten(), var[i].flatten()), 10 ** yspace)\n",
    "\n",
    "ax2.set_yscale('log')\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_xlim(0, 1.1)\n",
    "ax2.set_xticks([0, 0.5, 1])\n",
    "ax2.set_title('MAP')\n",
    "ax2.set_xlabel('PDF')\n",
    "ax2.xaxis.set_label_coords(0, -0.15)\n",
    "ax1.yaxis.set_label_coords(-0.4, 0.5)\n",
    "ax1.set_ylabel(r'$D~(\\mu \\mathrm{m^2 / s})$')\n",
    "\n",
    "for i in range(3):\n",
    "    ax2.plot(xspace2, 10**mu[i] * np.ones(len(xspace2)), '--', linewidth = 2, color = colors[i])\n",
    "\n",
    "plt.plot()\n",
    "####-MAP plot\n",
    "\n",
    "####--average transition matrix\n",
    "P_avg = np.zeros((2, 2))\n",
    "cnt = 0\n",
    "\n",
    "paths = ['MSH2/5nM/results', 'MSH2/10nM/results']\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    for j in range(fnum[i]):\n",
    "        with open('{}/MAP{}_{}.pkl'.format(path, j+1, 'AIC'), 'rb') as f:\n",
    "            temp = pickle.load(f)\n",
    "            tempD, tempP = sample_sorting(temp, np.sqrt(len(temp)-1).astype(int))\n",
    "            \n",
    "ax1.tick_params(which = 'major', labelsize = 15, direction = 'in', length = 7, bottom = True)\n",
    "ax1.tick_params(which = 'minor', direction = 'in', length = 5)\n",
    "ax2.tick_params(which = 'major', labelsize = 15, direction = 'in', length = 7, bottom = True)\n",
    "ax2.tick_params(which = 'minor', direction = 'in', length = 5)\n",
    "               \n",
    "               \n",
    "ax1.set_yticks([0.001, 0.01, 0.1, 1])\n",
    "ax2.set_yticks([0.001, 0.01, 0.1, 1])\n",
    "               \n",
    "               \n",
    "ax1.yaxis.set_minor_locator(ticker.LogLocator(base=10.0, subs=(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9), numticks=10))\n",
    "ax2.yaxis.set_minor_locator(ticker.LogLocator(base=10.0, subs=(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9), numticks=10))\n",
    "#ax2.yaxis.set_minor_locator(ticker.LogLocator(base=10.0, subs=(0.2, 0.4, 0.6, 0.8), numticks=5))\n",
    "\n",
    "#plt.savefig('AIC_clustering.pdf', format = 'pdf', dpi = 1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-variance",
   "metadata": {},
   "source": [
    "### Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "radical-orlando",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 187.5x187.5 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####--model histogram & plot setting\n",
    "\n",
    "gs = plt.GridSpec(1, 2, wspace = 0, width_ratios=[1, 1])\n",
    "fig = plt.figure(figsize = (2.5, 2.5))\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax2 = fig.add_subplot(gs[1], sharey = ax1)\n",
    "\n",
    "####--model histogram & plot setting\n",
    "\n",
    "####--BGMM, MLE & MLE plot\n",
    "\n",
    "Bayes_MLE_ds = np.array(Bayes_MLE_ds)\n",
    "bgmm = BGMM(n_components = 4,\n",
    "            max_iter = 50,\n",
    "            n_init = 20,\n",
    "            init_params = 'kmeans',\n",
    "            random_state = 1,\n",
    "            weight_concentration_prior = 20,\n",
    "            mean_precision_prior = 0.5,\n",
    "            covariance_type = 'spherical',\n",
    "            covariance_prior = 0.3,\n",
    "            degrees_of_freedom_prior = 5).fit(np.log10(Bayes_MLE_ds[:, None]))\n",
    "bgmm_labels = bgmm.predict(np.log10(Bayes_MLE_ds[:, None])) \n",
    "    \n",
    "mu = bgmm.means_\n",
    "var = bgmm.covariances_\n",
    "weights = bgmm.weights_\n",
    "\n",
    "hist, bins = np.histogram(np.log10(Bayes_MLE_ds), density = True, bins = np.linspace(-3, 0.5, 35))\n",
    "bins = (bins[:len(bins) - 1] + (bins[1] - bins[0]) / 2).copy()\n",
    "\n",
    "for i in range(3):\n",
    "    globals()['bound{}'.format(i+1)] = np.min(Bayes_MLE_ds[bgmm_labels == i])\n",
    "    globals()['bayesMLEbound{}'.format(i+1)] = np.min(Bayes_MLE_ds[bgmm_labels == i])\n",
    "    globals()['index{}'.format(i+1)] = np.where(globals()['bound{}'.format(i+1)] <= 10 ** bins)[0][0]\n",
    "\n",
    "ax1.barh(10**bins[index1:], hist[index1:], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index1:], color = colors[0], alpha = 0.4)\n",
    "ax1.barh(10**bins[index2:index1], hist[index2:index1], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index2:index1], color = colors[1], alpha = 0.4)\n",
    "ax1.barh(10**bins[index3:index2], hist[index3:index2], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index3:index2], color = colors[2], alpha = 0.4)\n",
    "#ax1.barh(10**bins[:index3], hist[:index3], height = (bins[1] - bins[0]) * 2.3 * 10**bins[:index3], color = colors[3], alpha = 0.4)\n",
    "\n",
    "ax1.invert_xaxis()\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xlim(1.1, 0)\n",
    "ax1.set_ylim(0.0005, 5)\n",
    "ax1.set_xticks([1, 0.5])\n",
    "ax1.set_title('MLE')\n",
    "ax1.tick_params(which = 'both', direction = 'in')\n",
    "\n",
    "xspace2 = np.linspace(1, 0, 5)\n",
    "for i in range(3):\n",
    "    ax1.plot(xspace2, 10**mu[i] * np.ones(len(xspace2)), '--', linewidth = 2, color = colors[i])\n",
    "\n",
    "####--BGMM, MLE & MLE plot\n",
    "\n",
    "####-MAP plot\n",
    "\n",
    "Bayes_MAP_ds = np.array(Bayes_MAP_ds)\n",
    "bgmm = BGMM(n_components = 4,\n",
    "            max_iter = 50,\n",
    "            n_init = 20,\n",
    "            init_params = 'kmeans',\n",
    "            random_state = 1,\n",
    "            weight_concentration_prior = 20,\n",
    "            mean_precision_prior = 0.5,\n",
    "            covariance_type = 'spherical',\n",
    "            covariance_prior = 0.3,\n",
    "            degrees_of_freedom_prior = 5).fit(np.log10(Bayes_MAP_ds[:, None]))\n",
    "bgmm_labels = bgmm.predict(np.log10(Bayes_MAP_ds[:, None])) \n",
    "    \n",
    "mu = bgmm.means_\n",
    "var = bgmm.covariances_\n",
    "weights = bgmm.weights_\n",
    "    \n",
    "hist, bins = np.histogram(np.log10(Bayes_MAP_ds), density = True, bins = np.linspace(-3, 0.5, 35))\n",
    "bins = (bins[:len(bins) - 1] + (bins[1] - bins[0]) / 2).copy()\n",
    "\n",
    "for i in range(3):\n",
    "    globals()['bound{}'.format(i+1)] = np.min(Bayes_MAP_ds[bgmm_labels == i])\n",
    "    globals()['bayesMAPbound{}'.format(i+1)] = np.min(Bayes_MAP_ds[bgmm_labels == i])\n",
    "    globals()['index{}'.format(i+1)] = np.where(globals()['bound{}'.format(i+1)] <= 10 ** bins)[0][0]\n",
    "\n",
    "ax2.barh(10**bins[index1:], hist[index1:], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index1:], color = colors[0], alpha = 0.4)\n",
    "ax2.barh(10**bins[index2:index1], hist[index2:index1], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index2:index1], color = colors[1], alpha = 0.4)\n",
    "ax2.barh(10**bins[index3:index2], hist[index3:index2], height = (bins[1] - bins[0]) * 2.3 * 10**bins[index3:index2], color = colors[2], alpha = 0.4)\n",
    "\n",
    "#yspace = np.linspace(-3, 0.2, 1000)\n",
    "#for i in range(len(mu)):\n",
    "#    ax2.plot(weights[i].flatten() * norm.pdf(yspace, mu[i].flatten(), var[i].flatten()), 10 ** yspace)\n",
    "\n",
    "ax2.set_yscale('log')\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_xlim(0, 1.1)\n",
    "ax2.set_xticks([0, 0.5, 1])\n",
    "ax2.set_title('MAP')\n",
    "ax2.set_xlabel('PDF')\n",
    "ax2.xaxis.set_label_coords(0, -0.15)\n",
    "ax2.tick_params(which = 'both', direction = 'in')\n",
    "\n",
    "ax1.yaxis.set_label_coords(-0.4, 0.5)\n",
    "ax1.set_ylabel(r'$D~(\\mu \\mathrm{m^2 / s})$')\n",
    "\n",
    "for i in range(3):\n",
    "    ax2.plot(xspace2, 10**mu[i] * np.ones(len(xspace2)), '--', linewidth = 2, color = colors[i])\n",
    "\n",
    "    \n",
    "ax1.tick_params(which = 'major', labelsize = 15, direction = 'in', length = 7, bottom = True)\n",
    "ax1.tick_params(which = 'minor', direction = 'in', length = 5)\n",
    "ax2.tick_params(which = 'major', labelsize = 15, direction = 'in', length = 7, bottom = True)\n",
    "ax2.tick_params(which = 'minor', direction = 'in', length = 5)\n",
    "               \n",
    "               \n",
    "ax1.set_yticks([0.001, 0.01, 0.1, 1])\n",
    "ax2.set_yticks([0.001, 0.01, 0.1, 1])\n",
    "               \n",
    "               \n",
    "ax1.yaxis.set_minor_locator(ticker.LogLocator(base=10.0, subs=(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9), numticks=10))\n",
    "ax2.yaxis.set_minor_locator(ticker.LogLocator(base=10.0, subs=(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9), numticks=10))\n",
    "\n",
    "plt.plot()\n",
    "\n",
    "####--average transition matrix\n",
    "P_avg = np.zeros((2, 2))\n",
    "cnt = 0\n",
    "\n",
    "paths = ['MSH2/5nM/results', 'MSH2/10nM/results']\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "    for j in range(fnum[i]):\n",
    "        with open('{}/MAP{}_{}.pkl'.format(path, j+1, 'AIC'), 'rb') as f:\n",
    "            temp = pickle.load(f)\n",
    "            tempD, tempP = sample_sorting(temp, np.sqrt(len(temp)-1).astype(int))\n",
    "            if len(tempD) == 2:\n",
    "                if bound1 <= tempD[1] and bound2 <= tempD[0] < bound1:\n",
    "                    P_avg += tempP\n",
    "                    cnt += 1\n",
    "P_avg /= cnt\n",
    "#print(P_avg)\n",
    "\n",
    "####--average transition matrix\n",
    "\n",
    "#plt.savefig('Bayes_clustering_appendix.pdf', format = 'pdf', dpi = 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-hawaii",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
