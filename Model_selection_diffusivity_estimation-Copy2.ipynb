{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e45721-e5ff-4ec8-a65c-5011466d2a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys, os, subprocess, shutil, glob, pathlib\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Interpreter:\", sys.executable)\n",
    "\n",
    "env_name = os.path.basename(sys.prefix) or \"current-env\"\n",
    "print(\"Detected environment name:\", env_name)\n",
    "\n",
    "req_file = \"requirements.txt\"\n",
    "if os.path.exists(req_file):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", req_file])\n",
    "else:\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
    "                           \"numpy==1.23.5\", \"scipy==1.15.3\",\n",
    "                           \"parmap==1.7.0\", \"pandas==2.3.1\",\n",
    "                           \"scikit-learn==1.7.1\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"setuptools>=68\", \"wheel\", \"Cython<3.1\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"ipykernel\", \"install\",\n",
    "                       \"--user\", \"--name\", env_name, \"--display-name\", f\"Python ({env_name})\"])\n",
    "\n",
    "for p in [\"build\", \"__pycache__\"]:\n",
    "    shutil.rmtree(p, ignore_errors=True)\n",
    "for f in glob.glob(\"ns_hmm.*.so\") + glob.glob(\"ns_hmm.*.pyd\") + glob.glob(\"ns_hmm.c\"):\n",
    "    pathlib.Path(f).unlink(missing_ok=True)\n",
    "\n",
    "for key in (\"CFLAGS\", \"CPPFLAGS\", \"CXXFLAGS\"):\n",
    "    if key in os.environ:\n",
    "        os.environ.pop(key)\n",
    "\n",
    "if os.path.exists(\"setup.py\"):\n",
    "    print(\"\\n[Build] python setup.py build_ext --inplace ...\")\n",
    "    subprocess.check_call([sys.executable, \"setup.py\", \"build_ext\", \"--inplace\"])\n",
    "else:\n",
    "    raise FileNotFoundError(\"setup.py not found in current directory.\")\n",
    "\n",
    "import importlib\n",
    "try:\n",
    "    import ns_hmm\n",
    "except Exception:\n",
    "    if \"ns_hmm\" in sys.modules:\n",
    "        del sys.modules[\"ns_hmm\"]\n",
    "    importlib.invalidate_caches()\n",
    "    import ns_hmm\n",
    "\n",
    "print(\"\\nSetup complete. ns_hmm loaded:\", ns_hmm)\n",
    "print(f\"Jupyter kernel registered as: Python ({env_name})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "from matplotlib import gridspec\n",
    "import multiprocessing\n",
    "from multiprocessing import get_context\n",
    "import parmap\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from sklearn.mixture import BayesianGaussianMixture as BGMM\n",
    "import sys, subprocess, shutil, glob, pathlib, os, site, platform, threading\n",
    "import pickle\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Interpreter:\", sys.executable)\n",
    "print(\"Site-packages:\", site.getsitepackages())\n",
    "print(\"OS:\", platform.platform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"times new roman\"\n",
    "plt.rcParams[\"mathtext.fontset\"] = \"cm\"\n",
    "plt.rcParams['figure.dpi'] = 75\n",
    "plt.rcParams['xtick.labelsize'] = 15\n",
    "plt.rcParams['ytick.labelsize'] = 15\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['axes.titlesize'] = 20 \n",
    "\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qualified-still",
   "metadata": {},
   "source": [
    "# Nested sampling run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1494851c-c672-4768-8ca3-95cb07052ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-configurable parameters\n",
    "user_params = {\n",
    "    \"D_min\": 0.001,\n",
    "    \"D_max\": 2.0,\n",
    "    \"unit_T\": 0.1,\n",
    "    \"unit_L\": 0.167,\n",
    "}\n",
    "path = 'test_dataset'\n",
    "\n",
    "ns_hmm.set_params(user_params)\n",
    "fnames = np.genfromtxt(f'{path}/filenames.txt', dtype=str)\n",
    "print(ns_hmm.get_params())  # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56398171-d615-4f11-b962-3a30f4297043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fnum = len(fnames)\n",
    "findices = np.arange(1, fnum + 1)\n",
    "num_cores = min(os.cpu_count(), fnum)\n",
    "indices = np.array_split(findices, num_cores)\n",
    "\n",
    "print(fnames)\n",
    "for i in range(fnum):\n",
    "    globals()[f'trj_{i+1}'] = np.genfromtxt(f'{path}/{fnames[i]}')\n",
    "\n",
    "def start_logger(ctx):\n",
    "    mgr = ctx.Manager()\n",
    "    q = mgr.Queue()\n",
    "    def _listener():\n",
    "        for msg in iter(q.get, None):\n",
    "            print(msg, flush=True)\n",
    "    t = threading.Thread(target=_listener, daemon=True)\n",
    "    t.start()\n",
    "    return q, t, mgr\n",
    "\n",
    "start_method = \"fork\" if sys.platform != \"win32\" else \"spawn\"\n",
    "ctx = get_context(start_method)\n",
    "\n",
    "USE_LOG_QUEUE = True\n",
    "log_q, t, mgr = (None, None, None)\n",
    "if USE_LOG_QUEUE:\n",
    "    log_q, t, mgr = start_logger(ctx)\n",
    "\n",
    "def _init_worker(params):\n",
    "    import ns_hmm as _m\n",
    "    _m.set_params(params)\n",
    "\n",
    "with ctx.Pool(processes=num_cores, initializer=_init_worker, initargs=(user_params,)) as pool:\n",
    "    results = parmap.map(\n",
    "        ns_hmm.mp_nested_sampling,\n",
    "        indices,\n",
    "        200, 100000, 0.0001, 0.25, 30, path,\n",
    "        log_q=log_q,\n",
    "        pm_pbar=True, pm_pool=pool\n",
    "    )\n",
    "\n",
    "if USE_LOG_QUEUE:\n",
    "    log_q.put(None)\n",
    "    t.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6079c610-9b22-4801-9574-21f75db29529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "assisted-scoop",
   "metadata": {},
   "source": [
    "# AIC calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC = np.zeros((fnum, 3))\n",
    "for j in range(fnum):\n",
    "    temp_AIC = np.inf\n",
    "    for k in range(3):\n",
    "        nstates = k + 1\n",
    "        with open('{}/results/{}totalseries{}state.pkl'.format(path, j+1, nstates), 'rb') as f:\n",
    "            temp = pickle.load(f)\n",
    "        temp_MLE = temp[np.argmax(temp[:, nstates**2]), :]\n",
    "        AIC[j, k] = 2 * (nstates ** 2) - 2 * temp_MLE[nstates ** 2]\n",
    "        \n",
    "        if AIC[j, k] < temp_AIC: # model selection\n",
    "            temp_AIC = AIC[j, k]\n",
    "            globals()['MLE{}'.format(j+1)] = temp_MLE.copy() # MLE with minimum AIC\n",
    "\n",
    "with open('{}/results/AIC.pkl'.format(path), 'wb') as f:\n",
    "    pickle.dump(AIC, f)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-satin",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AIC = np.zeros(fnum, dtype = int)\n",
    "with open('{}/results/AIC.pkl'.format(path), 'rb') as f:\n",
    "    IC = pickle.load(f)\n",
    "model_AIC = np.argmin(IC, axis = 1) + 1\n",
    "            \n",
    "model_Bayes = np.zeros(fnum, dtype = int)\n",
    "for i in range(fnum):\n",
    "    with open('{}/results/prob{}.pkl'.format(path, i + 1), 'rb') as f:\n",
    "        prob = pickle.load(f)\n",
    "    model_Bayes[i] = np.argmax(prob) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-browse",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5188bc6a-cf46-4e68-9264-3798054ae086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "interested-ranking",
   "metadata": {},
   "source": [
    "# Parameter estimation (MLE, MAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac067b6-931d-4e2d-a46b-779994788b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_hmm.NS_Params('uniform', 'AIC', path, fnum)\n",
    "ns_hmm.NS_Params('uniform', 'Bayesian', path, fnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "AIC_MLE_ds = []\n",
    "AIC_MAP_ds = []\n",
    "cnt = 0\n",
    "\n",
    "####--AIC, MLE\n",
    "\n",
    "for j in range(fnum):\n",
    "    with open('{}/results/MLE{}_{}.pkl'.format(path, j+1, 'AIC'), 'rb') as f:\n",
    "        temp = pickle.load(f)\n",
    "    temp = temp.flatten()\n",
    "    for k in range(np.sqrt(len(temp)-1).astype(int)):\n",
    "        AIC_MLE_ds.append(temp[k])\n",
    "        \n",
    "####--AIC, MLE\n",
    "\n",
    "####--AIC, MAP\n",
    "\n",
    "for j in range(fnum):\n",
    "    with open('{}/results/MAP{}_{}.pkl'.format(path, j+1, 'AIC'), 'rb') as f:\n",
    "        temp = pickle.load(f)\n",
    "    temp = temp.flatten()\n",
    "    for k in range(np.sqrt(len(temp)-1).astype(int)):\n",
    "        AIC_MAP_ds.append(temp[k])\n",
    "\n",
    "####--AIC, MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayes_MLE_ds = []\n",
    "Bayes_MAP_ds = []\n",
    "cnt = 0\n",
    "\n",
    "####--Bayes, MLE\n",
    "\n",
    "for j in range(fnum):\n",
    "    with open('{}/results/MLE{}_{}.pkl'.format(path, j+1, 'Bayesian'), 'rb') as f:\n",
    "        temp = pickle.load(f)\n",
    "    temp = temp.flatten()\n",
    "    for k in range(np.sqrt(len(temp)-1).astype(int)):\n",
    "        Bayes_MLE_ds.append(temp[k])\n",
    "        \n",
    "####--Bayes, MLE\n",
    "\n",
    "\n",
    "####--Bayes, MAP\n",
    "\n",
    "for j in range(fnum):\n",
    "    with open('{}/results/MAP{}_{}.pkl'.format(path, j+1, 'Bayesian'), 'rb') as f:\n",
    "        temp = pickle.load(f)\n",
    "    temp = temp.flatten()\n",
    "    for k in range(np.sqrt(len(temp)-1).astype(int)):\n",
    "        Bayes_MAP_ds.append(temp[k])\n",
    "\n",
    "####--Bayes, MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-blast",
   "metadata": {},
   "source": [
    "# Parameter clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-colon",
   "metadata": {},
   "source": [
    "### AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from sklearn.mixture import BayesianGaussianMixture as BGMM\n",
    "from scipy.stats import norm\n",
    "import pickle\n",
    "\n",
    "def _prep_positive_log10(arr, name=\"array\"):\n",
    "    arr = np.asarray(arr, dtype=float).ravel()\n",
    "    arr = arr[np.isfinite(arr) & (arr > 0)]\n",
    "    if arr.size == 0:\n",
    "        raise ValueError(f\"{name}\")\n",
    "    return np.log10(arr)\n",
    "\n",
    "def _safe_hist(log10_vals, bins_linspace):\n",
    "    hist, bins = np.histogram(log10_vals, density=True, bins=bins_linspace)\n",
    "    # bin center\n",
    "    binw = bins[1] - bins[0]\n",
    "    centers = bins[:-1] + binw/2\n",
    "    return hist, centers, binw\n",
    "\n",
    "def _boundaries_from_means(mu_log10):\n",
    "    mu = np.sort(np.asarray(mu_log10).ravel())[::-1]\n",
    "    mids = (mu[:-1] + mu[1:]) / 2.0\n",
    "    while len(mids) < 3:\n",
    "        mids = np.append(mids, mids[-1])\n",
    "    return mids[:3]\n",
    "\n",
    "def _bin_index_for_boundary(bound_log10, bin_centers_log10):\n",
    "    idx = np.searchsorted(bin_centers_log10, bound_log10, side=\"left\")\n",
    "    return int(np.clip(idx, 0, len(bin_centers_log10)))\n",
    "\n",
    "# --- plotting params\n",
    "colors = ['tab:red', 'tab:blue', 'tab:grey', 'tab:grey']\n",
    "\n",
    "gs = plt.GridSpec(1, 2, wspace=0, width_ratios=[1, 1])\n",
    "fig = plt.figure(figsize=(2.5, 2.5))\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax2 = fig.add_subplot(gs[1], sharey=ax1)\n",
    "\n",
    "# ===== BGMM, MLE =====\n",
    "AIC_MLE_ds = np.array(AIC_MLE_ds, dtype=float)\n",
    "log10_MLE = _prep_positive_log10(AIC_MLE_ds, name=\"AIC_MLE_ds\")\n",
    "\n",
    "bgmm_mle = BGMM(\n",
    "    n_components=4,\n",
    "    max_iter=50,\n",
    "    n_init=50,\n",
    "    init_params='kmeans',\n",
    "    random_state=1,\n",
    "    weight_concentration_prior=20,\n",
    "    mean_precision_prior=0.5,\n",
    "    covariance_type='spherical',\n",
    "    covariance_prior=0.3,\n",
    "    degrees_of_freedom_prior=5\n",
    ").fit(log10_MLE[:, None])\n",
    "\n",
    "labels_mle = bgmm_mle.predict(log10_MLE[:, None])\n",
    "mu_mle = bgmm_mle.means_.ravel()\n",
    "var_mle = bgmm_mle.covariances_.ravel()\n",
    "w_mle = bgmm_mle.weights_.ravel()\n",
    "\n",
    "for i in range(4):\n",
    "    count_i = np.count_nonzero(labels_mle == i)\n",
    "    print(count_i)\n",
    "    print('weight:', w_mle[i])\n",
    "    print('mu:', 10**mu_mle[i])\n",
    "    print('var:', var_mle[i])\n",
    "\n",
    "bins_lin = np.linspace(-3, 0.5, 35)\n",
    "hist_mle, centers_mle, binw_mle = _safe_hist(log10_MLE, bins_lin)\n",
    "\n",
    "bounds_mle_log10 = _boundaries_from_means(mu_mle)\n",
    "index1 = _bin_index_for_boundary(bounds_mle_log10[0], centers_mle)\n",
    "index2 = _bin_index_for_boundary(bounds_mle_log10[1], centers_mle)\n",
    "index3 = _bin_index_for_boundary(bounds_mle_log10[2], centers_mle)\n",
    "\n",
    "yvals_mle = 10**centers_mle\n",
    "hscale_mle = binw_mle * 2.3 * yvals_mle\n",
    "\n",
    "ax1.barh(yvals_mle[index1:], hist_mle[index1:], height=hscale_mle[index1:], color=colors[0], alpha=0.4)\n",
    "ax1.barh(yvals_mle[index2:index1], hist_mle[index2:index1], height=hscale_mle[index2:index1], color=colors[1], alpha=0.4)\n",
    "ax1.barh(yvals_mle[index3:index2], hist_mle[index3:index2], height=hscale_mle[index3:index2], color=colors[2], alpha=0.4)\n",
    "ax1.barh(yvals_mle[:index3], hist_mle[:index3], height=hscale_mle[:index3], color=colors[3], alpha=0.4)\n",
    "\n",
    "ax1.invert_xaxis()\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim(0.0005, 5)\n",
    "ax1.set_title('MLE')\n",
    "\n",
    "xspace2 = np.linspace(1, 0, 5)\n",
    "for i in range(3):\n",
    "    ax1.plot(xspace2, np.full_like(xspace2, 10**np.sort(mu_mle)[::-1][i]), '--', linewidth=2, color=colors[i])\n",
    "\n",
    "# ===== BGMM, MAP =====\n",
    "AIC_MAP_ds = np.array(AIC_MAP_ds, dtype=float)\n",
    "log10_MAP = _prep_positive_log10(AIC_MAP_ds, name=\"AIC_MAP_ds\")\n",
    "\n",
    "bgmm_map = BGMM(\n",
    "    n_components=4,\n",
    "    max_iter=50,\n",
    "    n_init=50,\n",
    "    init_params='kmeans',\n",
    "    random_state=1,\n",
    "    weight_concentration_prior=20,\n",
    "    mean_precision_prior=0.5,\n",
    "    covariance_type='spherical',\n",
    "    covariance_prior=0.3,\n",
    "    degrees_of_freedom_prior=5\n",
    ").fit(log10_MAP[:, None])\n",
    "\n",
    "labels_map = bgmm_map.predict(log10_MAP[:, None])\n",
    "mu_map = bgmm_map.means_.ravel()\n",
    "var_map = bgmm_map.covariances_.ravel()\n",
    "w_map = bgmm_map.weights_.ravel()\n",
    "\n",
    "for i in range(4):\n",
    "    count_i = np.count_nonzero(labels_map == i)\n",
    "    print(count_i)\n",
    "    print('weight:', w_map[i])\n",
    "    print('mu:', 10**mu_map[i])\n",
    "    print('var:', var_map[i])\n",
    "\n",
    "hist_map, centers_map, binw_map = _safe_hist(log10_MAP, bins_lin)\n",
    "bounds_map_log10 = _boundaries_from_means(mu_map)\n",
    "index1_map = _bin_index_for_boundary(bounds_map_log10[0], centers_map)\n",
    "index2_map = _bin_index_for_boundary(bounds_map_log10[1], centers_map)\n",
    "index3_map = _bin_index_for_boundary(bounds_map_log10[2], centers_map)\n",
    "\n",
    "yvals_map = 10**centers_map\n",
    "hscale_map = binw_map * 2.3 * yvals_map\n",
    "\n",
    "ax2.barh(yvals_map[index1_map:], hist_map[index1_map:], height=hscale_map[index1_map:], color=colors[0], alpha=0.4)\n",
    "ax2.barh(yvals_map[index2_map:index1_map], hist_map[index2_map:index1_map], height=hscale_map[index2_map:index1_map], color=colors[1], alpha=0.4)\n",
    "ax2.barh(yvals_map[index3_map:index2_map], hist_map[index3_map:index2_map], height=hscale_map[index3_map:index2_map], color=colors[2], alpha=0.4)\n",
    "\n",
    "ax2.set_yscale('log')\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_title('MAP')\n",
    "ax2.set_xlabel('PDF')\n",
    "ax2.xaxis.set_label_coords(0, -0.15)\n",
    "ax1.yaxis.set_label_coords(-0.4, 0.5)\n",
    "ax1.set_ylabel(r'$D~(\\mu \\mathrm{m^2 / s})$')\n",
    "\n",
    "for i in range(3):\n",
    "    ax2.plot(xspace2, np.full_like(xspace2, 10**np.sort(mu_map)[::-1][i]), '--', linewidth=2, color=colors[i])\n",
    "\n",
    "max_pdf_val_mle = max(\n",
    "    hist_mle[index1:].max(initial=0),\n",
    "    hist_mle[index2:index1].max(initial=0),\n",
    "    hist_mle[index3:index2].max(initial=0),\n",
    "    hist_mle[:index3].max(initial=0)\n",
    ")\n",
    "ax1.set_xlim(max_pdf_val_mle * 1.1, 0)\n",
    "\n",
    "max_pdf_val_map = max(\n",
    "    hist_map[index1_map:].max(initial=0),\n",
    "    hist_map[index2_map:index1_map].max(initial=0),\n",
    "    hist_map[index3_map:index2_map].max(initial=0)\n",
    ")\n",
    "ax2.set_xlim(0, max_pdf_val_map * 1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "P_avg = np.zeros((2, 2))\n",
    "cnt = 0\n",
    "\n",
    "for j in range(int(fnum)):\n",
    "    pkl_path = f'{path}/results/MAP{j+1}_AIC.pkl'\n",
    "    try:\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            temp = pickle.load(f)\n",
    "        win = int(np.sqrt(max(len(temp) - 1, 1)))\n",
    "        tempD, tempP = ns_hmm.sample_sorting(temp, win)\n",
    "        # P_avg += tempP; cnt += 1\n",
    "    except FileNotFoundError:\n",
    "        print(f\"path not found: {pkl_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"exception ({pkl_path}): {e}\")\n",
    "\n",
    "# if cnt > 0:\n",
    "#     P_avg /= cnt\n",
    "\n",
    "# ===== ticks & locators\n",
    "for ax in (ax1, ax2):\n",
    "    ax.tick_params(which='major', labelsize=15, direction='in', length=7, bottom=True)\n",
    "    ax.tick_params(which='minor', direction='in', length=5)\n",
    "    ax.set_yticks([0.001, 0.01, 0.1, 1])\n",
    "    ax.yaxis.set_minor_locator(ticker.LogLocator(base=10.0,\n",
    "        subs=(0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9), numticks=10))\n",
    "\n",
    "# plt.savefig('AIC_clustering.pdf', format='pdf', dpi=1200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affected-variance",
   "metadata": {},
   "source": [
    "### Bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from sklearn.mixture import BayesianGaussianMixture as BGMM\n",
    "import pickle\n",
    "\n",
    "# ===== helpers =====\n",
    "def _prep_log10_pos(arr, name):\n",
    "    arr = np.asarray(arr, float).ravel()\n",
    "    arr = arr[np.isfinite(arr) & (arr > 0)]\n",
    "    if arr.size == 0:\n",
    "        raise ValueError(f\"{name}\")\n",
    "    return np.log10(arr)\n",
    "\n",
    "def _safe_hist(log10_vals, bins_lin):\n",
    "    hist, bins = np.histogram(log10_vals, density=True, bins=bins_lin)\n",
    "    w = bins[1] - bins[0]\n",
    "    centers = bins[:-1] + w/2\n",
    "    return hist, centers, w\n",
    "\n",
    "def _bounds_from_means_linear(mu_log10, k=3):\n",
    "    mu = np.sort(np.asarray(mu_log10).ravel())[::-1]\n",
    "    mids = (mu[:-1] + mu[1:]) / 2.0\n",
    "    if mids.size == 0:\n",
    "        return np.array([np.nan, np.nan, np.nan])\n",
    "    while mids.size < k:\n",
    "        mids = np.append(mids, mids[-1])\n",
    "    return (10**mids[:k]).astype(float)\n",
    "\n",
    "def _seg_max(hist, i0=None, i1=None):\n",
    "    h = hist if (i0 is None and i1 is None) else hist[i0:i1]\n",
    "    return 0.0 if h.size == 0 else float(np.max(h))\n",
    "\n",
    "# ===== figure =====\n",
    "gs = plt.GridSpec(1, 2, wspace=0, width_ratios=[1, 1])\n",
    "fig = plt.figure(figsize=(2.5, 2.5))\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax2 = fig.add_subplot(gs[1], sharey=ax1)\n",
    "\n",
    "# ===== MLE =====\n",
    "log10_mle = _prep_log10_pos(Bayes_MLE_ds, \"Bayes_MLE_ds\")\n",
    "\n",
    "bgmm_mle = BGMM(\n",
    "    n_components=4, max_iter=50, n_init=20, init_params='kmeans',\n",
    "    random_state=1, weight_concentration_prior=20, mean_precision_prior=0.5,\n",
    "    covariance_type='spherical', covariance_prior=0.3, degrees_of_freedom_prior=5\n",
    ").fit(log10_mle[:, None])\n",
    "\n",
    "labels_mle = bgmm_mle.predict(log10_mle[:, None])\n",
    "mu_mle = bgmm_mle.means_.ravel()\n",
    "var_mle = bgmm_mle.covariances_.ravel()\n",
    "w_mle = bgmm_mle.weights_.ravel()\n",
    "\n",
    "for i in range(4):\n",
    "    print(np.count_nonzero(labels_mle == i))\n",
    "    print('weight:', w_mle[i])\n",
    "    print('mu:', 10**mu_mle[i])\n",
    "    print('var:', var_mle[i])\n",
    "\n",
    "bins_lin = np.linspace(-3, 0.5, 35)\n",
    "hist_mle, centers_mle, bw_mle = _safe_hist(log10_mle, bins_lin)\n",
    "yvals_mle = 10**centers_mle\n",
    "hscale_mle = bw_mle * 2.3 * yvals_mle\n",
    "\n",
    "bounds_mle = _bounds_from_means_linear(mu_mle, k=3)\n",
    "bound1, bound2, bound3 = bounds_mle\n",
    "globals()['bound1'] = bound1\n",
    "globals()['bound2'] = bound2\n",
    "globals()['bayesMLEbound1'] = bound1\n",
    "globals()['bayesMLEbound2'] = bound2\n",
    "globals()['bayesMLEbound3'] = bound3\n",
    "\n",
    "index1 = int(np.searchsorted(yvals_mle, bound1, side='left'))\n",
    "index2 = int(np.searchsorted(yvals_mle, bound2, side='left'))\n",
    "index3 = int(np.searchsorted(yvals_mle, bound3, side='left'))\n",
    "\n",
    "# barh\n",
    "ax1.barh(yvals_mle[index1:], hist_mle[index1:], height=hscale_mle[index1:], color=colors[0], alpha=0.4)\n",
    "ax1.barh(yvals_mle[index2:index1], hist_mle[index2:index1], height=hscale_mle[index2:index1], color=colors[1], alpha=0.4)\n",
    "ax1.barh(yvals_mle[index3:index2], hist_mle[index3:index2], height=hscale_mle[index3:index2], color=colors[2], alpha=0.4)\n",
    "# ax1.barh(yvals_mle[:index3], hist_mle[:index3], height=hscale_mle[:index3], color=colors[3], alpha=0.4)\n",
    "\n",
    "# 축/스타일\n",
    "ax1.invert_xaxis()\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_ylim(0.0005, 5)\n",
    "ax1.set_title('MLE')\n",
    "ax1.tick_params(which='both', direction='in')\n",
    "\n",
    "xspace2 = np.linspace(1, 0, 5)\n",
    "for i in range(3):\n",
    "    ax1.plot(xspace2, np.full_like(xspace2, 10**np.sort(mu_mle)[::-1][i]), '--', linewidth=2, color=colors[i])\n",
    "\n",
    "max_pdf_val_mle = max(\n",
    "    _seg_max(hist_mle, index1, None),\n",
    "    _seg_max(hist_mle, index2, index1),\n",
    "    _seg_max(hist_mle, index3, index2),\n",
    "    _seg_max(hist_mle, None, index3),\n",
    ")\n",
    "ax1.set_xlim(max_pdf_val_mle * 1.1, 0)\n",
    "\n",
    "# ===== MAP =====\n",
    "log10_map = _prep_log10_pos(Bayes_MAP_ds, \"Bayes_MAP_ds\")\n",
    "\n",
    "bgmm_map = BGMM(\n",
    "    n_components=4, max_iter=50, n_init=20, init_params='kmeans',\n",
    "    random_state=1, weight_concentration_prior=20, mean_precision_prior=0.5,\n",
    "    covariance_type='spherical', covariance_prior=0.3, degrees_of_freedom_prior=5\n",
    ").fit(log10_map[:, None])\n",
    "\n",
    "labels_map = bgmm_map.predict(log10_map[:, None])\n",
    "mu_map = bgmm_map.means_.ravel()\n",
    "var_map = bgmm_map.covariances_.ravel()\n",
    "w_map = bgmm_map.weights_.ravel()\n",
    "\n",
    "for i in range(4):\n",
    "    print(np.count_nonzero(labels_map == i))\n",
    "    print('weight:', w_map[i])\n",
    "    print('mu:', 10**mu_map[i])\n",
    "    print('var:', var_map[i])\n",
    "\n",
    "hist_map, centers_map, bw_map = _safe_hist(log10_map, bins_lin)\n",
    "yvals_map = 10**centers_map\n",
    "hscale_map = bw_map * 2.3 * yvals_map\n",
    "\n",
    "bounds_map = _bounds_from_means_linear(mu_map, k=3)\n",
    "bayesMAPbound1, bayesMAPbound2, bayesMAPbound3 = bounds_map\n",
    "globals()['bayesMAPbound1'] = bayesMAPbound1\n",
    "globals()['bayesMAPbound2'] = bayesMAPbound2\n",
    "globals()['bayesMAPbound3'] = bayesMAPbound3\n",
    "\n",
    "index1_map = int(np.searchsorted(yvals_map, bayesMAPbound1, side='left'))\n",
    "index2_map = int(np.searchsorted(yvals_map, bayesMAPbound2, side='left'))\n",
    "index3_map = int(np.searchsorted(yvals_map, bayesMAPbound3, side='left'))\n",
    "\n",
    "ax2.barh(yvals_map[index1_map:], hist_map[index1_map:], height=hscale_map[index1_map:], color=colors[0], alpha=0.4)\n",
    "ax2.barh(yvals_map[index2_map:index1_map], hist_map[index2_map:index1_map], height=hscale_map[index2_map:index1_map], color=colors[1], alpha=0.4)\n",
    "ax2.barh(yvals_map[index3_map:index2_map], hist_map[index3_map:index2_map], height=hscale_map[index3_map:index2_map], color=colors[2], alpha=0.4)\n",
    "\n",
    "ax2.set_yscale('log')\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_title('MAP')\n",
    "ax2.set_xlabel('PDF')\n",
    "ax2.xaxis.set_label_coords(0, -0.15)\n",
    "ax2.tick_params(which='both', direction='in')\n",
    "\n",
    "for i in range(3):\n",
    "    ax2.plot(xspace2, np.full_like(xspace2, 10**np.sort(mu_map)[::-1][i]), '--', linewidth=2, color=colors[i])\n",
    "\n",
    "max_pdf_val_mle = max(\n",
    "    hist_mle[index1:].max(initial=0),\n",
    "    hist_mle[index2:index1].max(initial=0),\n",
    "    hist_mle[index3:index2].max(initial=0),\n",
    "    hist_mle[:index3].max(initial=0)\n",
    ")\n",
    "ax1.set_xlim(max_pdf_val_mle * 1.1, 0)\n",
    "\n",
    "max_pdf_val_map = max(\n",
    "    hist_map[index1_map:].max(initial=0),\n",
    "    hist_map[index2_map:index1_map].max(initial=0),\n",
    "    hist_map[index3_map:index2_map].max(initial=0)\n",
    ")\n",
    "ax2.set_xlim(0, max_pdf_val_map * 1.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ===== average transition matrix =====\n",
    "P_avg = np.zeros((2, 2))\n",
    "cnt = 0\n",
    "for j in range(int(fnum)):\n",
    "    pkl_path = f'{path}/results/MAP{j+1}_AIC.pkl'\n",
    "    try:\n",
    "        with open(pkl_path, 'rb') as f:\n",
    "            temp = pickle.load(f)\n",
    "        win = int(np.sqrt(max(len(temp)-1, 1)))\n",
    "        tempD, tempP = ns_hmm.sample_sorting(temp, win)\n",
    "        if len(tempD) == 2:\n",
    "            if (globals()['bound1'] <= tempD[1]) and (globals()['bound2'] <= tempD[0] < globals()['bound1']):\n",
    "                P_avg += tempP\n",
    "                cnt += 1\n",
    "    except FileNotFoundError:\n",
    "        print(f\"path not found: {pkl_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"exception ({pkl_path}): {e}\")\n",
    "\n",
    "if cnt > 0:\n",
    "    P_avg /= cnt\n",
    "# print(P_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-hawaii",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
